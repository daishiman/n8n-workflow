# Step010: 業務理解フェーズ - 業務要件分析書

## 📋 概要

**分析日**: 2025-01-09
**ワークフロー名**: Google Meet議事録自動化
**業務目的**: Google DriveにアップロードされたM4A音声ファイルから自動で議事録を生成し、指定フォーマットで保存

---

## 🎯 業務要件サマリー

### ビジネス価値

1. **業務効率化**: 手動議事録作成時間を削減（1時間会議→5分で議事録生成）
2. **品質向上**: AIによる構造化された議事録（議題、決定事項、TODOの明確化）
3. **自動化**: Google Driveへのアップロード後、完全自動処理

### 処理対象

- **入力**: Google Drive上のM4A音声ファイル（会議録音）
- **出力**: Markdown形式の議事録
- **処理頻度**: 5分ごとのポーリングで新規ファイルを検知

---

## 🔄 処理フロー詳細分析

### 全体構造（12ノードグループ）

```
1. Google Drive Trigger（トリガー）
2. Google Drive: ファイル情報取得
3. Google Drive: M4Aファイルダウンロード
4. Google Gemini: 音声文字起こし（ネイティブ）
5. Code: チャンク分割（20-30行 + オーバーラップ）
6. Split in Batches: チャンク並列処理（5並列）
7. AI Agent Step1: 文字起こし整形（並列）
8. Merge: チャンク統合 + 重複除去
9. AI Agent Step2: 議題抽出
10. Code: 議題ごとのデータ再構成
11. Split in Batches: 議題並列処理（3並列）
12. AI Agent Step3: 議題分析（並列）
13. Merge: 議題統合
14. AI Agent Step4: フォーマット変換
15. AI Agent Step5: 品質保証
16. Google Drive: 議事録保存
17. Google Drive: M4Aファイル移動
18. Discord通知: 処理完了通知（オプション）
19. Error Workflow: エラーハンドリング
```

### ノードグループごとの役割

#### グループ1: トリガー & ファイル取得

**ノード**:
1. Google Drive Trigger
2. Google Drive: Get File Info

**目的**: 新規M4Aファイルの検知とメタデータ取得

**データフロー**:
```
Input: なし（トリガー）
Process: 5分ごとにGoogle Driveをポーリング
Output: {
  fileId: "xxx",
  fileName: "会議録.m4a",
  mimeType: "audio/m4a",
  createdTime: "2025-01-09T10:00:00Z",
  size: 123456789
}
```

#### グループ2: M4Aダウンロード

**ノード**:
3. Google Drive: M4Aファイルダウンロード

**目的**: M4A音声ファイルをバイナリデータとしてダウンロード

**データフロー**:
```
Input: ファイルメタデータ（fileId, downloadUrl）
Process: Google DriveからM4Aファイルをダウンロード
Output: M4Aバイナリデータ
```

#### グループ3: 音声文字起こし（Geminiネイティブ）

**ノード**:
4. Google Gemini: Transcribe Audio

**目的**: M4A音声ファイルを日本語テキストに変換（Geminiネイティブ機能）

**Google Gemini設定**:
- **Resource**: audio
- **Operation**: transcribe
- **Model**: Gemini 2.0 Flash
- **Features**:
  - Speaker Diarization: プロンプトベース（speaker A, B, C等）
  - Punctuation: 自動挿入
  - Timestamps: audioTimestamp=true で有効化
  - Max Duration: 8.4時間（1 million tokens）
- **認証**: `GOOGLE_API_KEY`
- **対応フォーマット**: audio/m4a, audio/mp3, audio/wav, audio/aac, audio/flac, audio/ogg

**データフロー**:
```
Input: M4Aバイナリデータ
Process: Gemini 2.0 Flashで文字起こし
Output: {
  lines: [
    {
      line_id: 1,
      content: "発言内容",
      speaker: "A",
      timestamp: "00:01:20",
      start_time: 80.5,
      end_time: 85.2
    },
    ...
  ],
  total_lines: 300
}
```

**主要な改善点**:
- ✅ Deepgram API不要（外部API削減）
- ✅ 処理時間50%短縮（60-120秒 → 30-60秒）
- ✅ コスト70-85%削減（Deepgram料金不要）
- ✅ 認証情報1つ削減（管理簡素化）

#### グループ4: チャンク分割（並列処理準備）

**ノード**:
5. Code: チャンク分割 + オーバーラップ追加

**目的**: 文字起こしテキストを20-30行ごとに分割、前後の文脈を確保

**ロジック**:
```javascript
// 擬似コード
const lines = transcript.split('\n');
const chunkSize = 25;  // 20-30行の中央値
const overlapSize = 6;  // 前後3チャンク（約6行）

const chunks = [];
for (let i = 0; i < lines.length; i += chunkSize) {
  chunks.push({
    chunk_id: Math.floor(i / chunkSize) + 1,
    main_text: lines.slice(i, i + chunkSize).join('\n'),
    overlap_before: i > 0 ? lines.slice(i - overlapSize, i).join('\n') : null,
    overlap_after: i + chunkSize < lines.length ? lines.slice(i + chunkSize, i + chunkSize + overlapSize).join('\n') : null,
    line_range: [i + 1, Math.min(i + chunkSize, lines.length)]
  });
}
```

**出力例（300行の場合）**:
```json
[
  {
    "chunk_id": 1,
    "main_text": "行1-25の内容...",
    "overlap_before": null,
    "overlap_after": "行26-31の内容...",
    "line_range": [1, 25]
  },
  {
    "chunk_id": 2,
    "main_text": "行26-50の内容...",
    "overlap_before": "行20-25の内容...",
    "overlap_after": "行51-56の内容...",
    "line_range": [26, 50]
  },
  ...
  {
    "chunk_id": 12,
    "main_text": "行276-300の内容...",
    "overlap_before": "行270-275の内容...",
    "overlap_after": null,
    "line_range": [276, 300]
  }
]
```

#### グループ5: Step1 - 文字起こし整形（並列処理）

**ノード**:
6. Split in Batches（Batch Size: 5）
7. AI Agent Step1: 文字起こし整形
8. Merge

**目的**: 各チャンクのフィラー除去と箇条書き化（5チャンク並列処理）

**AI Agent設定**:
- **Chat Model**: Google Gemini Flash 2.0
- **Memory**: なし（並列処理のため）
- **Temperature**: 0.4
- **Max Tokens**: 4000

**プロンプト例**:
```
以下の文字起こしテキストを整形してください：

【メインテキスト】
{main_text}

【前後の文脈（参考用）】
前: {overlap_before}
後: {overlap_after}

【指示】
1. フィラー語を除去（「えー」「あのー」「その」「まあ」等）
2. 意味のある文章単位で1行ずつ箇条書き化
3. 話者情報があれば保持
4. タイムスタンプを保持

【出力形式】
JSON配列で返してください：
[
  {
    "line_id": 1,
    "content": "整形後の文章",
    "speaker": 0,
    "timestamp": "00:01:20"
  },
  ...
]
```

**出力例（チャンク単位）**:
```json
[
  {
    "line_id": 1,
    "content": "プロジェクトの進捗について報告します",
    "speaker": 0,
    "timestamp": "00:01:20"
  },
  {
    "line_id": 2,
    "content": "現在の完成度は80%です",
    "speaker": 0,
    "timestamp": "00:01:25"
  }
]
```

**Mergeノードのロジック**:
```javascript
// 全チャンクの main_text のみを統合
const allLines = [];
for (const chunk of chunks) {
  // line_range を基準に統合（重複除去）
  allLines.push(...chunk.lines);
}

// line_id でソートして最終出力
allLines.sort((a, b) => a.line_id - b.line_id);
```

**統合後の出力**:
```json
[
  { "line_id": 1, "content": "...", "speaker": 0, "timestamp": "00:01:20" },
  { "line_id": 2, "content": "...", "speaker": 0, "timestamp": "00:01:25" },
  ...
  { "line_id": 300, "content": "...", "speaker": 2, "timestamp": "01:00:15" }
]
```

#### グループ6: Step2 - 議題抽出

**ノード**:
9. AI Agent Step2: 議題抽出

**目的**: 統合された文字起こしから議題を自動抽出

**AI Agent設定**:
- **Chat Model**: Google Gemini Flash 2.0
- **Memory**: あり（Simple Memory、session_key: `step2_memory`）
- **Temperature**: 0.4
- **Max Tokens**: 4000

**プロンプト例**:
```
以下の整形済み文字起こしから、会議の議題を抽出してください：

{統合JSON配列}

【指示】
1. 会話の流れから自然な議題の区切りを見つける
2. 各議題に適切なタイトルを付ける
3. 各議題に該当する行番号（line_id）を記録
4. 会議名も推測して抽出

【出力形式】
JSON配列で返してください：
{
  "meeting_name": "会議名（音声から抽出、なければファイル名から推測）",
  "agendas": [
    {
      "agenda_id": 1,
      "title": "議題タイトル",
      "line_ids": [1, 2, 3, 15, 16, 17]
    },
    ...
  ]
}
```

**出力例**:
```json
{
  "meeting_name": "プロジェクト定例会議",
  "agendas": [
    {
      "agenda_id": 1,
      "title": "プロジェクト進捗報告",
      "line_ids": [1, 2, 3, 4, 5, 10, 11, 25, 26]
    },
    {
      "agenda_id": 2,
      "title": "次回までのタスク確認",
      "line_ids": [30, 31, 32, 33, 40, 41]
    },
    {
      "agenda_id": 3,
      "title": "質疑応答",
      "line_ids": [50, 51, 52, 60, 61, 62, 63]
    }
  ]
}
```

#### グループ7: 議題ごとのデータ再構成

**ノード**:
10. Code: 議題ごとのデータ再構成

**目的**: 各議題に該当する全文字起こしを収集

**ロジック**:
```javascript
// Step2の議題JSON + Step1の統合JSONを入力
const agendas = step2Output.agendas;
const allLines = step1Output;  // 統合JSON配列

const reconstructedAgendas = agendas.map(agenda => {
  // 該当する line_ids の文字起こしを収集
  const lines = agenda.line_ids.map(id => {
    return allLines.find(line => line.line_id === id);
  });

  return {
    agenda_id: agenda.agenda_id,
    title: agenda.title,
    lines: lines,  // 該当する全文字起こし
    context: {
      total_lines: lines.length,
      duration: calculateDuration(lines)  // タイムスタンプから計算
    }
  };
});
```

**出力例**:
```json
[
  {
    "agenda_id": 1,
    "title": "プロジェクト進捗報告",
    "lines": [
      { "line_id": 1, "content": "...", "speaker": 0, "timestamp": "00:01:20" },
      { "line_id": 2, "content": "...", "speaker": 0, "timestamp": "00:01:25" },
      ...
    ],
    "context": {
      "total_lines": 9,
      "duration": "5分30秒"
    }
  },
  {
    "agenda_id": 2,
    "title": "次回までのタスク確認",
    "lines": [...],
    "context": {
      "total_lines": 6,
      "duration": "3分15秒"
    }
  }
]
```

#### グループ8: Step3 - 議題分析（並列処理）

**ノード**:
11. Split in Batches（Batch Size: 3）
12. AI Agent Step3: 議題分析
13. Merge

**目的**: 各議題から決定事項、宿題、保留事項を抽出（3議題並列処理）

**AI Agent設定**:
- **Chat Model**: Google Gemini Flash 2.0
- **Memory**: なし（並列処理のため）
- **Temperature**: 0.4
- **Max Tokens**: 4000

**プロンプト例**:
```
以下の議題に関する文字起こしから、決定事項、宿題、保留事項を抽出してください：

【議題】
{title}

【文字起こし】
{lines}

【指示】
1. 決定事項（decisions）: 明確に決まったこと
2. 宿題（todos）: 誰かが実施すべきタスク
3. 保留事項（pending）: 決定されなかった、または次回に持ち越す事項

【出力形式】
JSON形式で返してください：
{
  "agenda_id": 1,
  "decisions": ["決定事項1", "決定事項2"],
  "todos": ["宿題1", "宿題2"],
  "pending": ["保留事項1"]
}
```

**出力例（議題単位）**:
```json
{
  "agenda_id": 1,
  "decisions": [
    "リリース日を2月1日に確定",
    "開発環境はAWSを使用することを決定"
  ],
  "todos": [
    "開発チームが1月25日までにテストを完了させる",
    "デザインチームがUI素材を1月20日までに納品"
  ],
  "pending": []
}
```

**Mergeノードの出力（全議題統合）**:
```json
[
  {
    "agenda_id": 1,
    "title": "プロジェクト進捗報告",
    "decisions": ["リリース日を2月1日に確定"],
    "todos": ["開発チームが1月25日までにテストを完了させる"],
    "pending": []
  },
  {
    "agenda_id": 2,
    "title": "次回までのタスク確認",
    "decisions": [],
    "todos": ["議事録を1週間以内に共有"],
    "pending": ["予算の最終承認"]
  }
]
```

#### グループ9: Step4 - フォーマット変換

**ノード**:
14. AI Agent Step4: フォーマット変換

**目的**: 全データを統合し、指定フォーマットのMarkdown議事録を生成

**AI Agent設定**:
- **Chat Model**: Claude Sonnet 4.5
- **Memory**: あり（Simple Memory、session_key: `step4_memory`）
- **Temperature**: 0.7
- **Max Tokens**: 8000

**入力データ**:
```javascript
{
  meeting_name: step2Output.meeting_name,
  agendas: step3Output,  // 全議題の分析結果
  all_lines: step1Output,  // 全文字起こし
  file_metadata: {
    fileName: "会議録.m4a",
    createdTime: "2025-01-09T10:00:00Z",
    duration: "01:05:30"
  }
}
```

**プロンプト例**:
```
以下のデータから、指定フォーマットのMarkdown議事録を生成してください：

【データ】
- 会議名: {meeting_name}
- ファイル作成日時: {createdTime}
- 会議時間: {duration}
- 議題一覧: {agendas}
- 全文字起こし: {all_lines}

【指定フォーマット】
(業務要件定義書のフォーマットを貼り付け)

【指示】
1. 目的・背景: 文字起こしから会議の目的を推測
2. 日時: ファイル作成日時を使用、終了時刻は duration から計算
3. 参加者: 話者情報から推測、「万壽本」は必ず含める
4. 宿題事項: 全議題の todos を統合してリスト化
5. 決定事項: 全議題の decisions を統合してリスト化
6. 次回の日時: 文字起こしから次回日程を抽出、なければ「未定」
7. 本日の議題: 議題一覧をチェックボックス付きリストで記載
8. 議題N: 各議題の詳細を all_lines から該当部分を抽出して箇条書き化

【出力】
完全なMarkdownテキストを返してください。
```

**出力例**:
```markdown
# 目的・背景

プロジェクトの進捗状況を確認し、次回リリースに向けたタスクを明確化する。

# 日時

2025 年 01 月 09 日（木） 10:00 〜 11:05

# 参加者

田中（話者0）、佐藤（話者1）、鈴木（話者2）、万壽本

# 宿題事項

- 開発チームが1月25日までにテストを完了させる
- デザインチームがUI素材を1月20日までに納品
- 議事録を1週間以内に共有

# 決定事項

- リリース日を2月1日に確定
- 開発環境はAWSを使用することを決定

# 次回の日時

2025 年 01 月 16 日（木） 10:00 〜 11:00

# 議事内容

## 本日の議題

- [ ] 議題1：プロジェクト進捗報告
- [ ] 議題2：次回までのタスク確認
- [ ] 議題3：質疑応答

## 議題1：プロジェクト進捗報告

- プロジェクトの進捗について報告します
- 現在の完成度は80%です
- リリース日を2月1日に確定しました
- 開発環境はAWSを使用することを決定

## 議題2：次回までのタスク確認

- 開発チームが1月25日までにテストを完了させる
- デザインチームがUI素材を1月20日までに納品
- 議事録を1週間以内に共有

## 議題3：質疑応答

- 予算の最終承認は次回に持ち越し
- その他、質疑応答を実施
```

#### グループ10: Step5 - 品質保証

**ノード**:
15. AI Agent Step5: 品質保証

**目的**: 生成された議事録の完全性を検証し、不足項目を補完

**AI Agent設定**:
- **Chat Model**: Claude Sonnet 4.5
- **Memory**: あり（Simple Memory、session_key: `step5_memory`）
- **Temperature**: 0.7
- **Max Tokens**: 8000

**プロンプト例**:
```
以下の議事録の完全性を検証し、不足項目があれば補完してください：

【生成された議事録】
{step4_markdown}

【元データ】
- 全議題: {agendas}
- 全文字起こし: {all_lines}

【検証項目】
1. 必須項目が揃っているか（目的・背景、日時、参加者、宿題事項、決定事項、議事内容）
2. 各議題の内容が適切に記載されているか
3. 決定事項と宿題が漏れなく記載されているか
4. 文字起こしの重要な内容が抜けていないか

【指示】
- 問題がなければ、議事録をそのまま返す
- 不足があれば、補完した議事録を返す
- 重大な問題があれば、警告メッセージを含める

【出力形式】
{
  "status": "ok" | "補完実施" | "警告",
  "markdown": "最終議事録",
  "warnings": ["警告メッセージ1", ...]
}
```

**出力例**:
```json
{
  "status": "補完実施",
  "markdown": "（補完済みMarkdown）",
  "warnings": []
}
```

#### グループ11: 議事録保存 & ファイル移動

**ノード**:
16. Google Drive: 議事録保存
17. Google Drive: M4Aファイル移動

**目的**: 最終議事録の保存と元ファイルの整理

**Google Drive保存設定**:
- **保存先フォルダ**: `議事録_出力/`
- **ファイル名**: `minutes - {YYYY-MM-DD} - {会議名}.md`
  - 例: `minutes - 2025-01-09 - プロジェクト定例会議.md`
- **文字コード**: UTF-8
- **mimeType**: `text/markdown`

**Google Drive移動設定**:
- **移動元**: トリガーで検知したM4Aファイル
- **移動先**: `processed/` サブフォルダ
- **目的**: 処理済みファイルを区別、再処理を防ぐ

#### グループ12: 完了通知（オプション）

**ノード**:
18. Discord Webhook: 処理完了通知

**目的**: 議事録生成完了を管理者に通知

#### グループ13: エラーハンドリング（Error Workflow）

**ノード**:
19. Error Trigger（各ノードのエラー出力を受け取る）
20. Code: エラー情報整理
21. Conditional: エラー種別判定
22. Google Drive: エラーファイル移動（`/エラー/` フォルダ）
23. Discord Webhook: エラー通知

**エラー分類**:
1. **Gemini文字起こし失敗**: M4Aファイルを `/エラー/` に移動、管理者に通知
2. **AI処理失敗**: 部分生成された議事録を `[ERROR]minutes - ...` として保存、管理者に通知
3. **Google Drive失敗**: n8n内部ストレージに一時保存、リトライ（最大3回）

---

## 📊 データ構造設計

### Step1の出力（統合JSON）

```typescript
type TranscriptLine = {
  line_id: number;
  content: string;
  speaker: number;
  timestamp: string;  // "HH:MM:SS"
};

type Step1Output = TranscriptLine[];
```

### Step2の出力（議題JSON）

```typescript
type Agenda = {
  agenda_id: number;
  title: string;
  line_ids: number[];
};

type Step2Output = {
  meeting_name: string;
  agendas: Agenda[];
};
```

### Step3の出力（議題分析JSON）

```typescript
type AgendaAnalysis = {
  agenda_id: number;
  title: string;
  decisions: string[];
  todos: string[];
  pending: string[];
};

type Step3Output = AgendaAnalysis[];
```

### Step4-5の出力（Markdown）

```typescript
type MinutesOutput = {
  status: "ok" | "補完実施" | "警告";
  markdown: string;
  warnings: string[];
};
```

---

## ⚙️ 技術要件まとめ

### API/サービス依存

| サービス | 用途 | 認証方式 | 環境変数 |
|---------|------|---------|---------|
| Google Drive | トリガー、ファイル取得、保存 | OAuth2 | n8nで設定 |
| Google Gemini | 音声文字起こし + AI処理（Step0-3） | API Key | `GOOGLE_API_KEY` |
| Anthropic Claude | AI処理（Step4-5） | API Key | `ANTHROPIC_API_KEY` |
| Discord（オプション） | 完了通知・エラー通知 | Webhook URL | `DISCORD_WEBHOOK_URL` |

### パフォーマンス目標

| 項目 | 目標値 |
|------|--------|
| 1時間会議の処理時間 | **3分以内**（改善後） |
| 文字起こし | **30-60秒**（Gemini直接、50%短縮） |
| AI処理（Step1-5） | 2-3分 |
| 保存・移動 | 10秒 |

### バッチサイズ設定

| 処理 | バッチサイズ | 理由 |
|------|------------|------|
| チャンク並列処理（Step1） | 5 | APIレート制限を考慮 |
| 議題並列処理（Step3） | 3 | APIレート制限を考慮 |

---

## 🎯 次のステップ

**Step010完了**。次は **Step020: タスク分解フェーズ** に進みます。

業務要件を具体的なn8nノード単位のタスクに分解し、実装順序を決定します。
